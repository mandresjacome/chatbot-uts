import { GoogleGenerativeAI } from '@google/generative-ai';
import { isTeacherSearchQuery, findTeacherByName, formatTeacherInfo } from '../nlp/teacherSearch.js';

const USE_LLM = process.env.USE_LLM || 'gemini';
const MODEL = process.env.GEMINI_MODEL || 'gemini-2.5-flash';
const hasKey = Boolean(process.env.GEMINI_API_KEY);

const MAX_EVIDENCE = Number(process.env.MAX_CHARS_EVIDENCE || 2500);
const MAX_RESPONSE = Number(process.env.MAX_CHARS_RESPONSE || 1800);

// Recorta texto por caracteres (defensivo)
function cut(text = '', max = 2000) {
  if (!text) return '';
  return text.length > max ? text.slice(0, max) + '‚Ä¶' : text;
}

// Prompt "evidencia primero"
function buildPrompt({ question, evidenceChunks, userType }) {
  const system = [
    'Eres el Chatbot UTS v1.2.0 para las Unidades Tecnol√≥gicas de Santander.',
    'Responde √öNICAMENTE con la evidencia proporcionada.',
    'Si la evidencia no basta, pide datos concretos (programa, sede, periodo).',
    `Perfil del usuario: ${userType}.`,
    'Tono institucional, claro y conciso. Formatea con vi√±etas si ayuda.',
    'USA EMOJIS relevantes para hacer las respuestas m√°s visuales y atractivas.',
    'Incluye emojis al inicio de secciones importantes y en las vi√±etas.',
    'NO incluyas referencias ni menciones de fuentes en tu respuesta.',
  ].join(' ');

  const evidence = evidenceChunks.length
    ? evidenceChunks.map((c,i)=> `[#${i+1}] ${c.text}`).join('\n')
    : '(no hay evidencia disponible)';

  const body = [
    system,
    '',
    `Pregunta del usuario: ${question}`,
    '',
    'EVIDENCIA:',
    cut(evidence, MAX_EVIDENCE),
    '',
    `Redacta la mejor respuesta posible en <= ${MAX_RESPONSE} caracteres, fiel a la evidencia.`
  ].join('\n');

  return body;
}

// --- Cliente Gemini (si hay API key) ---
let genAI = null;
if (hasKey) {
  genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
}

export async function answerLLM({ question, evidenceChunks, userType }) {
  // Verificar si es una b√∫squeda de docente espec√≠fico
  if (isTeacherSearchQuery(question)) {
    // Buscar informaci√≥n de docentes en los chunks de evidencia
    const teacherChunk = evidenceChunks.find(chunk => 
      chunk.text.includes('DOCENTE') || 
      chunk.text.includes('Correo Institucional') ||
      chunk.text.toLowerCase().includes('docente') && chunk.text.includes('@uts.edu.co')
    );
    
    if (teacherChunk) {
      const teacher = findTeacherByName(question, teacherChunk.text);
      if (teacher) {
        return `¬°Informaci√≥n encontrada! üéì\n\n${formatTeacherInfo(teacher)}\n\nüìç **Programa:** Ingenier√≠a de Sistemas - UTS\n\n¬øTe gustar√≠a conocer algo m√°s espec√≠fico sobre este docente o el programa?`;
      }
    }
  }

  // Fallback mock o sin clave (funcionamiento original)
  if (USE_LLM === 'mock' || !hasKey) {
    if (!evidenceChunks?.length) {
      return `ü§î No tengo evidencia suficiente sobre "${question}". ` +
             `üìù Ind√≠came programa/sede/periodo para ayudarte mejor.`;
    }
    const bullets = evidenceChunks.map((c,i)=> `üìå ${c.text}`).join('\n');
    return `${bullets}\n\n‚ùì ¬øDeseas detalles para tu programa o sede espec√≠ficos?`;
  }

  // Gemini "evidencia primero" (funcionamiento original)
  const model = genAI.getGenerativeModel({ model: MODEL });

  const prompt = buildPrompt({ question, evidenceChunks, userType });
  const result = await model.generateContent({
    contents: [{ role: 'user', parts: [{ text: prompt }] }]
  });

  // Cortamos por seguridad/estilo
  const out = result?.response?.text?.() || '';
  return cut(out, MAX_RESPONSE);
}
